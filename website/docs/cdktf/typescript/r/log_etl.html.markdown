---
subcategory: "Log Service (SLS)"
layout: "alicloud"
page_title: "Alicloud: alicloud_log_etl"
sidebar_current: "docs-alicloud-resource-log-etl"
description: |-
  Provides a Alicloud log etl resource.
---


<!-- Please do not edit this file, it is generated. -->
# alicloud\_log\_etl

The data transformation of the log service is a hosted, highly available, and scalable data processing service, 
which is widely applicable to scenarios such as data regularization, enrichment, distribution, aggregation, and index reconstruction.
[Refer to details](https://www.alibabacloud.com/help/zh/doc-detail/125384.htm).

-> **NOTE:** Available in 1.120.0

## Example Usage

Basic Usage

```typescript
import * as constructs from "constructs";
import * as cdktf from "cdktf";
/*Provider bindings are generated by running cdktf get.
See https://cdk.tf/provider-generation for more details.*/
import * as alicloud from "./.gen/providers/alicloud";
class MyConvertedCode extends cdktf.TerraformStack {
  constructor(scope: constructs.Construct, name: string) {
    super(scope, name);
    const alicloudLogProjectExample = new alicloud.logProject.LogProject(
      this,
      "example",
      {
        description: "created by terraform",
        name: "tf-log",
      }
    );
    const alicloudLogStoreExample = new alicloud.logStore.LogStore(
      this,
      "example_1",
      {
        appendMeta: true,
        autoSplit: true,
        maxSplitShardCount: 60,
        name: "tf-test-logstore",
        project: cdktf.Token.asString(alicloudLogProjectExample.name),
        retentionPeriod: 3650,
        shardCount: 3,
      }
    );
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    alicloudLogStoreExample.overrideLogicalId("example");
    const alicloudLogStoreExample2 = new alicloud.logStore.LogStore(
      this,
      "example2",
      {
        appendMeta: true,
        autoSplit: true,
        maxSplitShardCount: 60,
        name: "tf-test-logstore-2",
        project: cdktf.Token.asString(alicloudLogProjectExample.name),
        retentionPeriod: 3650,
        shardCount: 3,
      }
    );
    const alicloudLogStoreExample3 = new alicloud.logStore.LogStore(
      this,
      "example3",
      {
        appendMeta: true,
        autoSplit: true,
        maxSplitShardCount: 60,
        name: "tf-test-logstore-3",
        project: cdktf.Token.asString(alicloudLogProjectExample.name),
        retentionPeriod: 3650,
        shardCount: 3,
      }
    );
    const alicloudLogEtlExample = new alicloud.logEtl.LogEtl(
      this,
      "example_4",
      {
        accessKeyId: "access_key_id",
        accessKeySecret: "access_key_secret",
        description: "etl_description",
        displayName: "display_name",
        etlName: "etl_name",
        etlSinks: [
          {
            accessKeyId: "example2_access_key_id",
            accessKeySecret: "example2_access_key_secret",
            endpoint: "cn-hangzhou.log.aliyuncs.com",
            logstore: cdktf.Token.asString(alicloudLogStoreExample2.name),
            name: "target_name",
            project: cdktf.Token.asString(alicloudLogProjectExample.name),
          },
          {
            accessKeyId: "example3_access_key_id",
            accessKeySecret: "example3_access_key_secret",
            endpoint: "cn-hangzhou.log.aliyuncs.com",
            logstore: cdktf.Token.asString(alicloudLogStoreExample3.name),
            name: "target_name2",
            project: cdktf.Token.asString(alicloudLogProjectExample.name),
          },
        ],
        logstore: cdktf.Token.asString(alicloudLogStoreExample.name),
        project: cdktf.Token.asString(alicloudLogProjectExample.name),
        script: "e_set('new','key')",
      }
    );
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    alicloudLogEtlExample.overrideLogicalId("example");
  }
}

```
Stop the task in progress
```
resource "alicloud_log_etl" "example" {
  status            = STOPPED
  etl_name          = "etl_name"
  project           = alicloud_log_project.example.name
  display_name      = "display_name"
  description       = "etl_description"
  access_key_id     = "access_key_id"
  access_key_secret = "access_key_secret"
  script            = "e_set('new','key')"
  logstore          = alicloud_log_store.example.name
  etl_sinks {
    name              = "target_name"
    access_key_id     = "example2_access_key_id"
    access_key_secret = "example2_access_key_secret"
    endpoint          = "cn-hangzhou.log.aliyuncs.com"
    project           = alicloud_log_project.example.name
    logstore          = alicloud_log_store.example2.name
  }
  etl_sinks {
    name              = "target_name2"
    access_key_id     = "example3_access_key_id"
    access_key_secret = "example3_access_key_secret"
    endpoint          = "cn-hangzhou.log.aliyuncs.com"
    project           = alicloud_log_project.example.name
    logstore          = alicloud_log_store.example3.name
  }
}
```
ReStart the stopped task
```
resource "alicloud_log_etl" "example" {
  status            = RUNNING
  etl_name          = "etl_name"
  project           = alicloud_log_project.example.name
  display_name      = "display_name"
  description       = "etl_description"
  access_key_id     = "access_key_id"
  access_key_secret = "access_key_secret"
  script            = "e_set('new','key')"
  logstore          = alicloud_log_store.example.name
  etl_sinks {
    name              = "target_name"
    access_key_id     = "example2_access_key_id"
    access_key_secret = "example2_access_key_secret"
    endpoint          = "cn-hangzhou.log.aliyuncs.com"
    project           = alicloud_log_project.example.name
    logstore          = alicloud_log_store.example2.name
  }
  etl_sinks {
    name              = "target_name2"
    access_key_id     = "example3_access_key_id"
    access_key_secret = "example3_access_key_secret"
    endpoint          = "cn-hangzhou.log.aliyuncs.com"
    project           = alicloud_log_project.example.name
    logstore          = alicloud_log_store.example3.name
  }
}
```

## Argument Reference

The following arguments are supported:

* `etlName` - (Required, ForceNew) The name of the log etl job.
* `description` - (Optional) Description of the log etl job.
* `project` - (Required, ForceNew) The name of the project where the etl job is located.
* `displayName` - (Required) Log service etl job alias.
* `schedule` - (Optional) Job scheduling type, the default value is Resident.
* `etlType` - (Optional) Log service etl type, the default value is `etl`.
* `status` - (Optional) Log project tags. the default value is RUNNING, Only 4 values are supported: `starting`，`running`，`stopping`，`stopped`.
* `createTime` - (Optional) The etl job create time.
* `lastModifiedTime` - (Optional) ETL job last modified time.
* `accessKeyId` - (Optional,Sensitive) Source logstore access key id.
* `kmsEncryptedAccessKeyId` - (Optional) An KMS encrypts access key id used to a log etl job. If the `accessKeyId` is filled in, this field will be ignored.
* `kmsEncryptionAccessKeyIdContext` - (Optional) An KMS encryption context used to decrypt `kmsEncryptedAccessKeyId` before creating or updating an instance with `kmsEncryptedAccessKeyId`. See [Encryption Context](https://www.alibabacloud.com/help/doc-detail/42975.htm). It is valid when `kmsEncryptedPassword` is set. When it is changed, the instance will reboot to make the change take effect.
* `accessKeySecret` - (Optional,Sensitive) Source logstore access key secret.
* `kmsEncryptedAccessKeySecret` - (Optional) An KMS encrypts access key secret used to a log etl job. If the `accessKeySecret` is filled in, this field will be ignored.
* `kmsEncryptionAccessKeySecretContext` - (Optional) An KMS encryption context used to decrypt `kmsEncryptedAccessKeySecret` before creating or updating an instance with `kmsEncryptedAccessKeySecret`. See [Encryption Context](https://www.alibabacloud.com/help/doc-detail/42975.htm). It is valid when `kmsEncryptedPassword` is set. When it is changed, the instance will reboot to make the change take effect.

* `fromTime` - (Optional) The start time of the processing job, if not set the value is 0, indicates to start processing from the oldest data.
* `toTime` - (Optional) Deadline of processing job, if not set the value is 0, indicates that new data will be processed continuously.
* `script` - (Required) Processing operation grammar.
* `version` - (Optional) Log etl job version. the default value is `2`.
* `logstore` - (Required) The source logstore of the processing job.
* `parameters` - (Optional) Advanced parameter configuration of processing operations.
* `roleArn` - (Optional) Sts role info under source logstore. `roleArn` and `(access_key_id, access_key_secret)` fill in at most one. If you do not fill in both, then you must fill in `(kms_encrypted_access_key_id, kms_encrypted_access_key_secret, kms_encryption_access_key_id_context, kms_encryption_access_key_secret_context)` to use KMS to get the key pair.
* `etlSinks` - (Required) Target logstore configuration for delivery after data processing.
    * `accessKeyId` - (Optional,Sensitive) Delivery target logstore access key id.
    * `kmsEncryptedAccessKeyId` - (Optional) An KMS encrypts access key id used to a log etl job. If the `accessKeyId` is filled in, this field will be ignored.
    * `accessKeySecret`- (Optional,Sensitive) Delivery target logstore access key secret.
    * `kmsEncryptedAccessKeySecret` - (Optional) An KMS encrypts access key secret used to a log etl job. If the `accessKeySecret` is filled in, this field will be ignored.
    * `endpoint` - (Required) Delivery target logstore region.
    * `name` - (Required) Delivery target name.
    * `project` - (Required) The project where the target logstore is delivered.
    * `logstore` - (Required) Delivery target logstore.
    * `roleArn` - (Optional) Sts role info under delivery target logstore. `roleArn` and `(access_key_id, access_key_secret)` fill in at most one. If you do not fill in both, then you must fill in `(kms_encrypted_access_key_id, kms_encrypted_access_key_secret, kms_encryption_access_key_id_context, kms_encryption_access_key_secret_context)` to use KMS to get the key pair.
    * `type` - (Optional)  ETL sinks type, the default value is AliyunLOG.
    
-> **Note:** `fromTime` and `toTime` no modification allowed after successful creation.

## Attributes Reference

The following attributes are exported:

* `id` - The ID of the log etl. It formats of `<project>:<etl_name>`.

### Timeouts

The `timeouts` block allows you to specify [timeouts](https://www.terraform.io/docs/configuration-0-11/resources.html#timeouts) for certain actions:

* `create` - (Defaults to 2 mins) Used when Creating LogEtl instance. 
* `delete` - (Defaults to 3 mins) Used when terminating the LogEtl instance. 
* `update` - (Defaults to 5 mins) Used when Updating LogEtl instance. 


## Import

Log etl can be imported using the id, e.g.

```shell
$ terraform import alicloud_log_etl.example tf-log-project:tf-log-etl-name
```

<!-- cache-key: cdktf-0.17.0-pre.15 input-a99f99357d1021771e06f414fdc8df8a20d83251d745a394fb586585fb8945fb -->